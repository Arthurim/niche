{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as urllib2\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from urllib.request import Request, urlopen\n",
    "import datetime\n",
    "import bs4\n",
    "from fake_useragent import UserAgent\n",
    "import re \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "%matplotlib inline  \n",
    "pd.set_option('display.max_columns', None)\n",
    "from time import sleep\n",
    "os.environ[\"PATH\"] =\"C:\\dev\\chromedriver;C:\\dev;\" + os.environ['PATH']\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do\n",
    "1. R - Get the content of the post from the post page (find preview from page with list of psots OR find the right html balise)\n",
    "2. R - Improve price finding function\n",
    "3. R - Find model etc\n",
    "4. TGP - see if not down and do stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REDDIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_url = \"https://www.reddit.com/r/Gear4Sale/?count=25&after=t3_kqnp3f\"\n",
    "path=\"C:/dev/niche/guitar/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(section):\n",
    "    a_s=section.findAll(\"a\")\n",
    "    for a in a_s:\n",
    "        if a.has_attr('href'):\n",
    "            # the first link is the right one\n",
    "            return a[\"href\"]\n",
    "        #TODO check link is valid\n",
    "\n",
    "def validate_string(s):\n",
    "    is_s=False\n",
    "    if type(s)==str:\n",
    "        if s!=\"\":\n",
    "            is_s =True\n",
    "    return is_s\n",
    "\n",
    "def find_vintage(content):\n",
    "    result = \"\"\n",
    "    # from 1985\n",
    "    if \"from \" in content:\n",
    "        split_on_from =  content.split(\"from \")\n",
    "        if len(split_on_from)==2:\n",
    "            #\"guitar from 1985\"\n",
    "            year = split_on_from[1][:4]\n",
    "            # still check that we are returning a number\n",
    "            if year.isdigit():\n",
    "                if int(four_char)>1900:\n",
    "                    result = year\n",
    "        else:\n",
    "            # \"guitar from the best from 1985\"\n",
    "            for i in range(len(split_on_from)):\n",
    "                year = split_on_from[i][:4]\n",
    "                # still check that we are returning a number\n",
    "                if year.isdigit():\n",
    "                    if int(four_char)>1900:\n",
    "                        result = year\n",
    "    else:\n",
    "        potential_years = []\n",
    "        for i in range(len(content)):\n",
    "            four_char = content[i:i+4]\n",
    "            if four_char.isdigit():\n",
    "                if int(four_char)>1900:\n",
    "                    potential_years.append(four_char)\n",
    "        if len(potential_years)==1:\n",
    "            # \"guitar blabla 1985\"\n",
    "            return potential_years\n",
    "        else:\n",
    "            # \"guitar made in 1985, bought in 2001\"\n",
    "            result = min(potential_years)\n",
    "    return result\n",
    "        # TODO check for \"made in\", \"manufactured in\" etc\n",
    "\n",
    "def find_longest_string_of_digits(s):\n",
    "    i=0\n",
    "    n = len(s)\n",
    "    while s[i].isdigit() or (s[i]==\".\") or (s[i]==\",\"):\n",
    "        i+=1\n",
    "        if (i==n):\n",
    "            break\n",
    "    return s[:i]\n",
    "\n",
    "def find_price(content):\n",
    "    ### TODO \"price\", \"price is\", \"USD\", \"usd\"\n",
    "    if \"price is \" in content:\n",
    "        split_on_price_is = content.split(\"price is \")\n",
    "        if len(split_on_price_is)==2:\n",
    "            # price is 300,45\n",
    "            # find \n",
    "            return find_longest_string_of_digits(split_on_price_is[1])\n",
    "        else:\n",
    "            ps = []\n",
    "            # price is 45.00. price is negotiable:\n",
    "            for i in range(len(split_on_price_is)):\n",
    "                print(split_on_price_is[i])\n",
    "                longest_digit = find_longest_string_of_digits(split_on_price_is[i])\n",
    "                if longest_digit!=\"\":\n",
    "                    ps.append(longest_digit)\n",
    "            if len(ps)==1:\n",
    "                return ps[0]\n",
    "            else:\n",
    "                return ps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.reddit.com/r/Gear4Sale/comments/kpn8tx/wts_vester_concert_series_2_from_1985_with/\n",
      "1985\n",
      "1985\n",
      "-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WTS Vester concert series 2 from 1985 with DiM...</td>\n",
       "      <td>http://imgur.com/gallery/hloDV53</td>\n",
       "      <td>https://www.reddit.com/r/Gear4Sale/comments/kp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  WTS Vester concert series 2 from 1985 with DiM...   \n",
       "\n",
       "                            content  \\\n",
       "0  http://imgur.com/gallery/hloDV53   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.reddit.com/r/Gear4Sale/comments/kp...  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(reddit_url)\n",
    "soup = bs4.BeautifulSoup(response.text, 'html.parser')\n",
    "list_of_posts=soup.findAll(\"div\", {\"class\":\"rpBJOHq2PR60pnwJlUyP0\"})[0].findAll(\"div\")\n",
    "\n",
    "df=pd.DataFrame(columns=[\"title\",\"content\",\"url\"])#,\"price\",\"brand\",\"model\"])\n",
    "k=0\n",
    "for section in t[0:len(list_of_posts)]:\n",
    "    try:\n",
    "        if section.text!=\"\":\n",
    "            post_title = section.findAll(\"h3\")[0].text\n",
    "            post_content = section.find(\"p\").text\n",
    "            # get url\n",
    "            post_url = get_url(section)\n",
    "            # just in case the section is empty, do check title and content are legitimate strings\n",
    "            if validate_string(post_title) and validate_string(post_content):\n",
    "                # Check for tags:\n",
    "                # only keep WTS, discard WTT and WTB\n",
    "                if (\"WTS\" in post_title) and not ((df['title'] == post_title)).any():\n",
    "                    # go to post_url\n",
    "                    post_response = requests.get(post_url)\n",
    "                    post_soup = bs4.BeautifulSoup(post_response.text, 'html.parser')\n",
    "                    content = post_soup.text\n",
    "                    vintage = find_vintage(post_title)\n",
    "                    if vintage ==\"\":\n",
    "                        vintage = find_vintage(content)\n",
    "                    print(post_url)\n",
    "                    print(vintage)\n",
    "                    print(\"-----\")\n",
    "                    # find price ?\n",
    "                    # find place ?\n",
    "                    # find brand\n",
    "                    # find year\n",
    "                    new_row = [post_title,post_content,post_url]\n",
    "                    # Check that we don't already have that post in our data\n",
    "                    if not ((df['title'] == post_title) & (df['content'] == post_content)).any():\n",
    "                        df.loc[k]=new_row\n",
    "                        k+=1\n",
    "\n",
    "    except Exception as error:\n",
    "        pass\n",
    "df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
