{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapper for guitar selling posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script scraps both *The Gear Page* forum and the *Gear4Sale* subreddit for posts selling guitars.\n",
    "For now the below characteristics are scrapped:\n",
    "- brand\n",
    "- price\n",
    "- vintage\n",
    "- color\n",
    "- wood\n",
    "\n",
    "To do:\n",
    "- scrap model\n",
    "- create database\n",
    "- compute average/median price\n",
    "- scrap prices from other places ?\n",
    "- define if a model is \"a good buy opportunity\"\n",
    "\n",
    "It then saves the posts in a csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FYI Persistence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrappedGuitars:([] id:`symbol$();brand:`symbol$();model:`symbol$();price:`float$();vintage:`int$();color:`symbol$();wood:`symbol$();website:`symbol$();url:();title:();content:())\n",
    "recommendedGuitars:([] id:`symbol$())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be sure to have the below path created, or to modify it for the data to be saved where you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"C:/dev/niche/guitar/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be sure to be able to import the below packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "from qpython import qconnection\n",
    "import requests\n",
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(section):\n",
    "    a_s=section.findAll(\"a\")\n",
    "    for a in a_s:\n",
    "        if a.has_attr('href'):\n",
    "            # the first link is the right one\n",
    "            return a[\"href\"]\n",
    "        #TODO check link is valid\n",
    "\n",
    "def validate_string(s):\n",
    "    \"\"\"\n",
    "    Returns True if:\n",
    "        - s is a string\n",
    "    &\n",
    "        - s is not an empty string\n",
    "    \"\"\"\n",
    "    is_s=False\n",
    "    if type(s)==str:\n",
    "        if s!=\"\":\n",
    "            is_s =True\n",
    "    return is_s\n",
    "\n",
    "def find_vintage(content):\n",
    "    result = \"\"\n",
    "    content = content.lower()\n",
    "    # from 1985\n",
    "    if \"from \" in content:\n",
    "        split_on_from =  content.split(\"from \")\n",
    "        if len(split_on_from)==2:\n",
    "            #\"guitar from 1985\"\n",
    "            year = split_on_from[1][:4]\n",
    "            # still check that we are returning a number\n",
    "            if year.isdigit():\n",
    "                if check_vintage(year):\n",
    "                    result = year\n",
    "        else:\n",
    "            # \"guitar from the best from 1985\"\n",
    "            for i in range(len(split_on_from)):\n",
    "                year = split_on_from[i][:4]\n",
    "                # still check that we are returning a number\n",
    "                if year.isdigit():\n",
    "                    if check_vintage(year):\n",
    "                        result = year\n",
    "    else: \n",
    "        potential_years = []\n",
    "        for i in range(len(content)):\n",
    "            if len(content[i:])>4:\n",
    "                four_char = content[i:i+4]\n",
    "                if four_char.isdigit():\n",
    "                    if check_vintage(four_char):\n",
    "                        potential_years.append(four_char)\n",
    "            if len(potential_years)==1:\n",
    "                # \"guitar blabla 1985\"\n",
    "                result=potential_years[0]\n",
    "            elif len(potential_years)>1:\n",
    "                # \"guitar made in 1985, bought in 2001\"\n",
    "                result = min(potential_years)\n",
    "    return result\n",
    "        # TODO check for \"made in\", \"manufactured in\" etc\n",
    "\n",
    "def find_longest_string_of_digits(s):\n",
    "    \"\"\"\n",
    "    from a string, assuming the first character is a digit, will return the longest number\n",
    "    eg:\n",
    "    - \"1234 frefr\" -> \"1234\"\n",
    "    - \"j 12345 p\" -> \"\"\n",
    "    \n",
    "    :s: string\n",
    "    \"\"\"\n",
    "    i=0\n",
    "    n = len(s)\n",
    "    if n>0:\n",
    "        while (s[i].isdigit() or (s[i]==\".\") or (s[i]==\",\")) and (i<n-1):\n",
    "            i+=1\n",
    "            if (i==n):\n",
    "                break\n",
    "        return s[:i]\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "def find_price(content):\n",
    "    result = \"\"\n",
    "    content = content.lower()\n",
    "    if \"price is \" in content:\n",
    "        split_on_price_is = content.split(\"price is \")\n",
    "        if len(split_on_price_is)==2:\n",
    "            # price is 300,45\n",
    "            # find\n",
    "            p = find_longest_string_of_digits(split_on_price_is[1][find_ind_of_next_digit_in_string(split_on_price_is[1]):])\n",
    "            if check_price(p):\n",
    "                result = p\n",
    "        else:\n",
    "            ps = []\n",
    "            # price is 45.00. price is negotiable:\n",
    "            for i in range(len(split_on_price_is)):\n",
    "                print(split_on_price_is[i])\n",
    "                longest_digit = find_longest_string_of_digits(split_on_price_is[i])\n",
    "                if longest_digit!=\"\":\n",
    "                    if check_price(longest_digit):\n",
    "                        ps.append(longest_digit)\n",
    "            if len(ps)==1:\n",
    "                result = ps[0]\n",
    "            elif len(ps)>1:\n",
    "                result = ps[0]\n",
    "    for sign in [\"usd\", \"$\", \"price\"]:\n",
    "        if sign in content:\n",
    "            split_on_dollar_sign = content.split(sign)\n",
    "            p = find_longest_string_of_digits(split_on_dollar_sign[1][find_ind_of_next_digit_in_string(split_on_dollar_sign[1]):])\n",
    "            if p.isdigit():\n",
    "                if check_price(p):\n",
    "                    return p\n",
    "    return result\n",
    "\n",
    "def check_price(p,lb=100,ub=5000):\n",
    "    if type(p)==str:\n",
    "        p = float(p.replace(\",\",\"\"))\n",
    "    return p>lb  and p <ub\n",
    "\n",
    "def check_vintage(v):\n",
    "    if type(v)==str:\n",
    "        v=int(v)\n",
    "    return v>1900 and v<2021\n",
    "\n",
    "def find_ind_of_next_digit_in_string(s):\n",
    "    \"\"\"\n",
    "    Returns the index of the next character which is a digit\n",
    "    \n",
    "    eg:\n",
    "    - \"Ah 1\" -> 3\n",
    "    - \"2\" -> 0\n",
    "    - \"ABC\" -> None\n",
    "    \n",
    "    \"\"\"\n",
    "    for i in range(len(s)):\n",
    "        if s[i].isdigit():\n",
    "            return i\n",
    "        \n",
    "def get_brand_and_model(brand_models,s):\n",
    "    \"\"\"\n",
    "    s: string, content to look into\n",
    "    brand_models:dict, eg:\n",
    "        {\"brand1\":[\"model1\",\"model2\"],\n",
    "        \"brand2\":[\"model1\",\"model2\"],\n",
    "        \"brand3\":[\"model1\",\"model2\"],}\n",
    "        \n",
    "    return: {\"brand\":[\"brand1\",\"brand2\"], \"model\":[\"model1\",\"model2\"]}\n",
    "    \"\"\"\n",
    "    result={\"brand\":[],\"model\":[]}\n",
    "    for brand in brand_models.keys():\n",
    "        if brand in s:\n",
    "            result[\"brand\"].append(brand)\n",
    "    if result[\"brand\"]!=[]:\n",
    "        for brand in result[\"brand\"]:\n",
    "            for model in brand_models[brand]:\n",
    "                if model in s:\n",
    "                    result[\"model\"].append(model)\n",
    "    return result\n",
    "\n",
    "def get_brand_model_from_title_content(brand_models, title, content):\n",
    "    brand=\"\"\n",
    "    model=\"\"\n",
    "    brand_model = get_brand_and_model(brand_models, title)\n",
    "    if len(brand_model[\"brand\"])==1:\n",
    "        brand = brand_model[\"brand\"][0]\n",
    "    if len(brand_model[\"model\"])==1:\n",
    "        model = brand_model[\"model\"][0]\n",
    "    \n",
    "    # if I did not manage to get brand from title, then get it from content\n",
    "    if brand==\"\":\n",
    "        brand_model = get_brand_and_model(brand_models, content)\n",
    "        if len(brand_model[\"brand\"])==1:\n",
    "            brand = brand_model[\"brand\"][0]\n",
    "        # and get model as well\n",
    "        if len(brand_model[\"model\"])==1:\n",
    "            model = brand_model[\"model\"][0]    \n",
    "    return brand, model\n",
    "\n",
    "def get_brand(content):\n",
    "    brands = pd.read_csv(path+\"guitar_brands.csv\")[\"Brand\"].tolist()\n",
    "    result = \"\"\n",
    "    content = content.lower()\n",
    "    for brand in brands:\n",
    "        if brand in content:\n",
    "            return brand\n",
    "    return result\n",
    "\n",
    "def get_model(content,brand):\n",
    "    # TODO: for each brand get a list of the models and save it in a csv: brand_models.csv\n",
    "    result = \"\"\n",
    "    models = []#pd.read_csv(path+brand+\"_models.csv\")[\"Model\"].tolist()\n",
    "    content = content.lower()\n",
    "    for model in models:\n",
    "        if model in content:\n",
    "            return model\n",
    "    return result\n",
    "    \n",
    "def find_color(s):\n",
    "    for c in [\"blue\", \"red\", \"yellow\", \"pink\", \"green\", \"purple\", \"white\", \"grey\", \"black\", \"beige\", \"orange\"]:\n",
    "        if c in s:\n",
    "            return c\n",
    "        \n",
    "def get_wood(s):\n",
    "    # TODO: improve this function by getting the wood for the different parts:\n",
    "    #eg:\n",
    "    #   Top: Basswood\n",
    "    #   Body: Basswood\n",
    "    #   Neck: Mahogany\n",
    "    #   Fingerboard: Rosewood\n",
    "    #   Nut: Bone\n",
    "    \n",
    "    woods = [\"alder\",\"basswod\",\"magahony\",\"swamp ash\", \"walnut\",\"koa\",\"mapple\",\"rosewood\",\"ebony\",\"wenge\"]\n",
    "    result = \"\"\n",
    "    s=s.lower()\n",
    "    for wood in woods:\n",
    "        if wood in s:\n",
    "            return wood\n",
    "    if \"neck wood\" in s:\n",
    "        split_on_neck_wood = s.split(\"neck wood\")\n",
    "    return result\n",
    "\n",
    "def find_relevant_information(content,title,url,post_date):\n",
    "    # [\"brand\",\"model\",\"price\",\"vintage\",\"color\",\"wood\",\"post_date\", \"post_title\",\"post_content\",\"post_url\"]\n",
    "    new_row = []\n",
    "    \n",
    "    # find vintage\n",
    "    vintage = find_vintage(title)\n",
    "    if vintage ==\"\":\n",
    "        vintage = find_vintage(content)\n",
    "    # find price\n",
    "    price = find_price(content)\n",
    "\n",
    "    # If we have price, find brand, model, wood, color\n",
    "    if price!=\"\":\n",
    "\n",
    "        # find brand\n",
    "        brand = get_brand(content)\n",
    "        if brand==\"\":\n",
    "            brand = get_brand(title)\n",
    "        # find model\n",
    "        model = get_model(content, brand)\n",
    "        if model==\"\":\n",
    "            model = get_model(content, brand)\n",
    "        # find color\n",
    "        color = find_color(content)\n",
    "        # find wood\n",
    "        wood = get_wood(content)\n",
    "\n",
    "        # create a new pd.Df row and insert it if not only there\n",
    "        new_row=[brand,model,price, vintage,color,wood,post_date,title,content,url,]\n",
    "        \n",
    "    return new_row\n",
    "\n",
    "def scrap_brands_from_wikipedia():\n",
    "    \"\"\"\n",
    "    Scrapp all guitar brands from wikipedia and saves it into a file\n",
    "    \"\"\"\n",
    "    brands = []\n",
    "    wikipedia_url = \"https://en.wikipedia.org/wiki/List_of_guitar_manufacturers\"\n",
    "    wikipedia_rep = requests.get(wikipedia_url)\n",
    "    wikipedia_soup = bs4.BeautifulSoup(wikipedia_rep.text, 'html.parser')\n",
    "    lis = wikipedia_soup.findAll(\"div\",{\"class\": \"div-col\", \"style\":\"column-width: 22em;\"})[0].findAll(\"li\")\n",
    "    for li in lis:\n",
    "        a_s = li.findAll(\"a\")\n",
    "        if len(a_s)>0:\n",
    "            if a_s[0].has_attr('title'):\n",
    "                title = str(a_s[0][\"title\"]).lower()\n",
    "                # machin (bidule) -> machin\n",
    "                title = title.split(\" (\")[0]\n",
    "                # machin guitars -> machin\n",
    "                title = title.split(\" guitars\")[0]\n",
    "                title = title.split(\" guitar\")[0]\n",
    "                # machin music -> machin\n",
    "                title = title.split(\" music\")[0]\n",
    "                brands.append(title)\n",
    "    pd.DataFrame(brands, columns=[\"Brand\"]).to_csv(path+\"guitar_brands.csv\", index=False)\n",
    "    return brands\n",
    "\n",
    "def kdb_format_year(year):\n",
    "    year = str(year)\n",
    "    y = \"\"\n",
    "    for char in year:\n",
    "        if char.isdigit():\n",
    "            y+=char\n",
    "    year=y\n",
    "    if year==\"None\" or year ==\"\":\n",
    "        return \"0Ni\"\n",
    "    else:\n",
    "        return year+\"i\"\n",
    "    \n",
    "def insert_scrappedGuitars_into_kdb(df):\n",
    "    for index, row in df.iterrows():\n",
    "        kdb_row  = str(row[\"post_date\"])+\";\"+\\\n",
    "            \"`\"+str(uuid4()).replace(\"-\",\"\")+\";\"+\\\n",
    "            \"`$\\\"\"+str(row[\"brand\"])+\"\\\"\"+\";\"+\\\n",
    "            \"`$\\\"\"+str(row[\"model\"])+\"\\\"\"+\";\"+\\\n",
    "            str(float(row[\"price\"].replace(\",\",\"\")))+\";\"+\\\n",
    "            kdb_format_year(str(row[\"vintage\"]))+\";\"+\\\n",
    "            \"`$\\\"\"+str(row[\"color\"])+\"\\\"\"+\";\"+\\\n",
    "            \"`$\\\"\"+str(row[\"wood\"])+\"\\\"\"+\";\"+\\\n",
    "            \"`$\\\"\"+str(row[\"website\"])+\"\\\"\"+\";\"+\\\n",
    "            \"\\\"\"+str(row[\"post_url\"])+\"\\\"\"+\";\"+\\\n",
    "            \"\\\"\"+str(row[\"post_title\"]).replace(\"\\\"\",\"\").replace(u\"\\u2019\",\" \")+\"\\\"\"\n",
    "\n",
    "        with qconnection.QConnection(host = \"localhost\",port=41643, username=\"n1ch3\", password=\"n1ch3\", pandas = True) as q:\n",
    "            #scrappedGuitars:([] date:`date$();id:`symbol$();brand:`symbol$();model:`symbol$();price:`float$();vintage:`int$();color:`symbol$();wood:`symbol$();website:`symbol$();url:();title:())\n",
    "            try:\n",
    "                X=q('upsert[`scrappedGuitarsToday;('+ kdb_row +')]')\n",
    "            except Exception as error:\n",
    "                print(error)\n",
    "                print('('+ kdb_row +')')\n",
    "                print(\"___\")\n",
    "                break\n",
    "                \n",
    "def init_kdb_instance():\n",
    "    init=\"\"\"\n",
    "    scrappedGuitarsToday:([] date:`date$();id:`symbol$();brand:`symbol$();model:`symbol$();price:`float$();vintage:`int$();color:`symbol$();wood:`symbol$();website:`symbol$();url:();title:());\n",
    "    recommendedGuitarsToday:([] date:`date$();id:`symbol$());\n",
    "    \n",
    "    hdbDirectory : `$\"c:/dev/niche/kdb\";\n",
    "    system \"l \",string hdbDirectory;\n",
    "    rollToHdb:{[hdbDirectory;data;targetDate]\n",
    "        dataTargetDate:select from data where date=targetDate;\n",
    "        if[0<count dataTargetDate;\n",
    "            $[2<count cols dataTargetDate;\n",
    "                [`scrappedGuitars set `brand`model xasc delete date from data;\n",
    "                .Q.dpft[hsym hdbDirectory;targetDate;`brand;`scrappedGuitars]];\n",
    "                [`recommendedGuitars set `id xasc delete date from data;\n",
    "                .Q.dpft[hsym hdbDirectory;targetDate;`id;`recommendedGuitars]]\n",
    "                ];\n",
    "            ];\n",
    "        };\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    with qconnection.QConnection(host = \"localhost\",port=41643, username=\"n1ch3\", password=\"n1ch3\", pandas = True) as q:\n",
    "            try:\n",
    "                X=q(init)\n",
    "            except Exception as error:\n",
    "                print(error)\n",
    "\n",
    "def roll_to_HDB_all_dates():\n",
    "    roll = \"rollToHdb[hdbDirectory;scrappedGuitarsToday;] each exec distinct date from scrappedGuitarsToday;\"+\\\n",
    "           \"rollToHdb[hdbDirectory;recommendedGuitarsToday;] each exec distinct date from recommendedGuitarsToday;\"\n",
    "    with qconnection.QConnection(host = \"localhost\",port=41643, username=\"n1ch3\", password=\"n1ch3\", pandas = True) as q:\n",
    "        try:\n",
    "            X=q(roll)\n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "            \n",
    "def roll_to_HDB_today_only():\n",
    "    roll = \"rollToHdb[hdbDirectory;scrappedGuitarsToday;.z.D]\" +\\\n",
    "           \"rollToHdb[hdbDirectory;recommendedGuitarsToday;.z.D]\"\n",
    "    with qconnection.QConnection(host = \"localhost\",port=41643, username=\"n1ch3\", password=\"n1ch3\", pandas = True) as q:\n",
    "        try:\n",
    "            X=q(roll)\n",
    "        except Exception as error:\n",
    "            print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REDDIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to scrap The Gear Page, processing the first 5 pages.\n",
      "... 20.0% done\n",
      "... 40.0% done\n",
      "... 60.0% done\n",
      "... 80.0% done\n",
      "... 100.0% done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>price</th>\n",
       "      <th>vintage</th>\n",
       "      <th>color</th>\n",
       "      <th>wood</th>\n",
       "      <th>post_date</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_content</th>\n",
       "      <th>post_url</th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>250</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>2021.01.19</td>\n",
       "      <td>WTS: Avalanche Run V2 LE Black/White Sparkle</td>\n",
       "      <td>Just an awesome color for this pedal. Mint con...</td>\n",
       "      <td>https://www.reddit.com/r/Gear4Sale/comments/l0...</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>230</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>2021.01.17</td>\n",
       "      <td>WTS Seymour Duncan Jeff Loomis pickup set</td>\n",
       "      <td>https://photos.app.goo.gl/FgspRpYN8GJq3s5w5\\n\\...</td>\n",
       "      <td>https://www.reddit.com/r/Gear4Sale/comments/ky...</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ibanez</td>\n",
       "      <td></td>\n",
       "      <td>130</td>\n",
       "      <td></td>\n",
       "      <td>red</td>\n",
       "      <td></td>\n",
       "      <td>2021.01.16</td>\n",
       "      <td>[WTS/WTT] [US-CA] TC Flashback X4, TC Quintess...</td>\n",
       "      <td>r/titlegore, right?\\n\\nI've made a lot of chan...</td>\n",
       "      <td>https://www.reddit.com/r/Gear4Sale/comments/ky...</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>350</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>2021.01.16</td>\n",
       "      <td>WTS Pro Tools | Duet by Apogee</td>\n",
       "      <td>Pics &amp;amp; timestamp: [https://imgur.com/a/GPY...</td>\n",
       "      <td>https://www.reddit.com/r/Gear4Sale/comments/kx...</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>600</td>\n",
       "      <td>1978</td>\n",
       "      <td>red</td>\n",
       "      <td></td>\n",
       "      <td>2021.01.14</td>\n",
       "      <td>WTS: Korg EMX-1SD and ESX-1 Electribes. Teenag...</td>\n",
       "      <td>Looking to unload some of my favorite pieces t...</td>\n",
       "      <td>https://www.reddit.com/r/Gear4Sale/comments/kx...</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aria</td>\n",
       "      <td></td>\n",
       "      <td>1700</td>\n",
       "      <td>2017</td>\n",
       "      <td>red</td>\n",
       "      <td>alder</td>\n",
       "      <td>2021.01.12</td>\n",
       "      <td>WTS/WTT Kiesel Vader V6 2017 Aquaburst Headles...</td>\n",
       "      <td>ImageURL: [https://imgur.com/a/hFR7shH](https:...</td>\n",
       "      <td>https://www.reddit.com/r/Gear4Sale/comments/kv...</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>200</td>\n",
       "      <td>2020</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>2021.01.11</td>\n",
       "      <td>WTS 2020 Mu-Tron Microtron IV $200</td>\n",
       "      <td>Excellent-near mint condition, velcro on back....</td>\n",
       "      <td>https://www.reddit.com/r/Gear4Sale/comments/ku...</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>eko</td>\n",
       "      <td></td>\n",
       "      <td>150</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>2021.01.11</td>\n",
       "      <td>WTS/WTT Eko Jazz Bass</td>\n",
       "      <td>Looking to locally sell or trade a made in Chi...</td>\n",
       "      <td>https://www.reddit.com/r/Gear4Sale/comments/ku...</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>660</td>\n",
       "      <td></td>\n",
       "      <td>red</td>\n",
       "      <td></td>\n",
       "      <td>2021.01.09</td>\n",
       "      <td>WTS: Moog Grandmother Semi-Modular Synth</td>\n",
       "      <td>Picture: [https://imgur.com/a/HoAFmhX](https:/...</td>\n",
       "      <td>https://www.reddit.com/r/Gear4Sale/comments/kt...</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>425</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>2021.01.09</td>\n",
       "      <td>[WTS] Maschine mk3</td>\n",
       "      <td>[US] Maschine Mk3 (used)\\n\\nUsed Maschine Mk3 ...</td>\n",
       "      <td>https://www.reddit.com/r/Gear4Sale/comments/kt...</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gc</td>\n",
       "      <td></td>\n",
       "      <td>135</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>2021.01.05</td>\n",
       "      <td>WTS/WTT: Assorted Guitar Pedals</td>\n",
       "      <td>[https://imgur.com/a/vDBGh9J](https://imgur.co...</td>\n",
       "      <td>https://www.reddit.com/r/Gear4Sale/comments/kq...</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>floyd rose</td>\n",
       "      <td></td>\n",
       "      <td>300</td>\n",
       "      <td>1985</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>2021.01.04</td>\n",
       "      <td>WTS Vester concert series 2 from 1985 with DiM...</td>\n",
       "      <td>http://imgur.com/gallery/hloDV53\\n\\nAMA\\nI'm i...</td>\n",
       "      <td>https://www.reddit.com/r/Gear4Sale/comments/kp...</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fender</td>\n",
       "      <td></td>\n",
       "      <td>200</td>\n",
       "      <td></td>\n",
       "      <td>red</td>\n",
       "      <td></td>\n",
       "      <td>2021.01.02</td>\n",
       "      <td>[WTS] American Standard Strat, Whammy V, Pedal...</td>\n",
       "      <td>**Pedals:**\\n\\n**~~SOLD~~** [~~Vox Wah Classic...</td>\n",
       "      <td>https://www.reddit.com/r/Gear4Sale/comments/ko...</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>esp</td>\n",
       "      <td></td>\n",
       "      <td>1000</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>2021.01.01</td>\n",
       "      <td>WTS Gibson, Martin, Fender, Strymon, Arturia b...</td>\n",
       "      <td>https://imgur.com/gallery/jKTGdzX\\n\\nI have a ...</td>\n",
       "      <td>https://www.reddit.com/r/Gear4Sale/comments/kn...</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>700</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>2020.12.31</td>\n",
       "      <td>[WTS] Tokai x Honda Sound Works electric guitar</td>\n",
       "      <td>{{SOLD}}\\n\\n[~~https://imgur.com/a/j3hpFqm~~](...</td>\n",
       "      <td>https://www.reddit.com/r/Gear4Sale/comments/kn...</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>600</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>2020.12.30</td>\n",
       "      <td>WTS: Digitakt, OBNE Minim, OBNE Visitor, Russi...</td>\n",
       "      <td>https://i.imgur.com/YCnTuom.jpg\\n\\nI'm looking...</td>\n",
       "      <td>https://www.reddit.com/r/Gear4Sale/comments/km...</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>180</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>2020.12.30</td>\n",
       "      <td>[WTS] Fulltone CS-OCD-Ge; Friedman BE-OD LTD -...</td>\n",
       "      <td>Fulltone CS-OCD-Ge: $180 OBO Shipped CONUS\\n\\n...</td>\n",
       "      <td>https://www.reddit.com/r/Gear4Sale/comments/km...</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1500</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>2020.12.28</td>\n",
       "      <td>WTS Pioneer DJM 900 NXS DJ mixer w/ Pelican case</td>\n",
       "      <td>Like New Condition - Asking $1500 OBO - comes ...</td>\n",
       "      <td>https://www.reddit.com/r/Gear4Sale/comments/kl...</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>schecter</td>\n",
       "      <td></td>\n",
       "      <td>499</td>\n",
       "      <td></td>\n",
       "      <td>red</td>\n",
       "      <td>rosewood</td>\n",
       "      <td>2020.12.24</td>\n",
       "      <td>[WTS] Schecter C-1 Platinum Satin Transparent ...</td>\n",
       "      <td>&amp;amp;#x200B;\\n\\n**Photo Album/Time Stamp:** [h...</td>\n",
       "      <td>https://www.reddit.com/r/Gear4Sale/comments/ki...</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>290</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>2020.12.23</td>\n",
       "      <td>WTS: Ableton Live 10 Suite (full edition, not ...</td>\n",
       "      <td>I am posting here to sell my **Ableton Live 10...</td>\n",
       "      <td>https://www.reddit.com/r/Gear4Sale/comments/ki...</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>150</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>2020.12.22</td>\n",
       "      <td>WTS Keeley Caverns V2</td>\n",
       "      <td>SOLD!\\n\\n[https://imgur.com/a/6ZL59N5](https:/...</td>\n",
       "      <td>https://www.reddit.com/r/Gear4Sale/comments/kh...</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>830</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>2020.12.21</td>\n",
       "      <td>WTS: AEA R84 Ribbon Microphone</td>\n",
       "      <td>Hi all,\\n\\nLooking to sell an AEA R84 in mint ...</td>\n",
       "      <td>https://www.reddit.com/r/Gear4Sale/comments/kh...</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>175</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>2020.12.20</td>\n",
       "      <td>WTS: Walrus Arp 87 (limited retro edition), JH...</td>\n",
       "      <td>WTS: \\n\\n[https://imgur.com/a/Rj6V8FH](https:/...</td>\n",
       "      <td>https://www.reddit.com/r/Gear4Sale/comments/kg...</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>280</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>2020.12.20</td>\n",
       "      <td>WTS - ventris, deco, faceless fx</td>\n",
       "      <td>https://imgur.com/gallery/QoIz565\\n\\nHey guys,...</td>\n",
       "      <td>https://www.reddit.com/r/Gear4Sale/comments/kg...</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ibanez</td>\n",
       "      <td></td>\n",
       "      <td>240</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>rosewood</td>\n",
       "      <td>2020.12.20</td>\n",
       "      <td>WTS/WTT - USA-CA - Washburn Rover Travel Guita...</td>\n",
       "      <td>[pretty, pretty gallery](https://imgur.com/a/0...</td>\n",
       "      <td>https://www.reddit.com/r/Gear4Sale/comments/kg...</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>200</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>2020.12.12</td>\n",
       "      <td>WTS - Faceless fx, r2r treble booster</td>\n",
       "      <td>http://imgur.com/8bzw4aU\\n\\nAll prices shipped...</td>\n",
       "      <td>https://www.reddit.com/r/Gear4Sale/comments/kb...</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>danelectro</td>\n",
       "      <td></td>\n",
       "      <td>110</td>\n",
       "      <td></td>\n",
       "      <td>red</td>\n",
       "      <td></td>\n",
       "      <td>2020.12.12</td>\n",
       "      <td>WTS: JHS, Analogman, DOD, Spruce Effects, Dane...</td>\n",
       "      <td>Wampler Tumnus - $110\\n\\nJHS Moonshine - $100\\...</td>\n",
       "      <td>https://www.reddit.com/r/Gear4Sale/comments/kb...</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>275</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>2020.12.11</td>\n",
       "      <td>WTS Pigtronix Infinity Looper, Hungry Robot Mo...</td>\n",
       "      <td>Pic w/ date [https://imgur.com/FrqLmGi](https:...</td>\n",
       "      <td>https://www.reddit.com/r/Gear4Sale/comments/ka...</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>130</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>2020.12.10</td>\n",
       "      <td>WTS MXR M87 Bass Compressor</td>\n",
       "      <td>Asking for $130 + shipping, it's in like new c...</td>\n",
       "      <td>https://www.reddit.com/r/Gear4Sale/comments/ka...</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         brand model price vintage color      wood   post_date  \\\n",
       "0                      250          None            2021.01.19   \n",
       "1                      230          None            2021.01.17   \n",
       "2       ibanez         130           red            2021.01.16   \n",
       "3                      350          None            2021.01.16   \n",
       "4                      600    1978   red            2021.01.14   \n",
       "5         aria        1700    2017   red     alder  2021.01.12   \n",
       "6                      200    2020  None            2021.01.11   \n",
       "7          eko         150          None            2021.01.11   \n",
       "8                      660           red            2021.01.09   \n",
       "9                      425          None            2021.01.09   \n",
       "10          gc         135          None            2021.01.05   \n",
       "11  floyd rose         300    1985  None            2021.01.04   \n",
       "12      fender         200           red            2021.01.02   \n",
       "13         esp        1000          None            2021.01.01   \n",
       "14                     700          None            2020.12.31   \n",
       "15                     600          None            2020.12.30   \n",
       "16                     180          None            2020.12.30   \n",
       "17                    1500          None            2020.12.28   \n",
       "18    schecter         499           red  rosewood  2020.12.24   \n",
       "19                     290          None            2020.12.23   \n",
       "20                     150          None            2020.12.22   \n",
       "21                     830          None            2020.12.21   \n",
       "22                     175          None            2020.12.20   \n",
       "23                     280          None            2020.12.20   \n",
       "24      ibanez         240          None  rosewood  2020.12.20   \n",
       "25                     200          None            2020.12.12   \n",
       "26  danelectro         110           red            2020.12.12   \n",
       "27                     275          None            2020.12.11   \n",
       "28                     130          None            2020.12.10   \n",
       "\n",
       "                                           post_title  \\\n",
       "0        WTS: Avalanche Run V2 LE Black/White Sparkle   \n",
       "1           WTS Seymour Duncan Jeff Loomis pickup set   \n",
       "2   [WTS/WTT] [US-CA] TC Flashback X4, TC Quintess...   \n",
       "3                      WTS Pro Tools | Duet by Apogee   \n",
       "4   WTS: Korg EMX-1SD and ESX-1 Electribes. Teenag...   \n",
       "5   WTS/WTT Kiesel Vader V6 2017 Aquaburst Headles...   \n",
       "6                  WTS 2020 Mu-Tron Microtron IV $200   \n",
       "7                               WTS/WTT Eko Jazz Bass   \n",
       "8            WTS: Moog Grandmother Semi-Modular Synth   \n",
       "9                                  [WTS] Maschine mk3   \n",
       "10                    WTS/WTT: Assorted Guitar Pedals   \n",
       "11  WTS Vester concert series 2 from 1985 with DiM...   \n",
       "12  [WTS] American Standard Strat, Whammy V, Pedal...   \n",
       "13  WTS Gibson, Martin, Fender, Strymon, Arturia b...   \n",
       "14    [WTS] Tokai x Honda Sound Works electric guitar   \n",
       "15  WTS: Digitakt, OBNE Minim, OBNE Visitor, Russi...   \n",
       "16  [WTS] Fulltone CS-OCD-Ge; Friedman BE-OD LTD -...   \n",
       "17   WTS Pioneer DJM 900 NXS DJ mixer w/ Pelican case   \n",
       "18  [WTS] Schecter C-1 Platinum Satin Transparent ...   \n",
       "19  WTS: Ableton Live 10 Suite (full edition, not ...   \n",
       "20                              WTS Keeley Caverns V2   \n",
       "21                     WTS: AEA R84 Ribbon Microphone   \n",
       "22  WTS: Walrus Arp 87 (limited retro edition), JH...   \n",
       "23                   WTS - ventris, deco, faceless fx   \n",
       "24  WTS/WTT - USA-CA - Washburn Rover Travel Guita...   \n",
       "25              WTS - Faceless fx, r2r treble booster   \n",
       "26  WTS: JHS, Analogman, DOD, Spruce Effects, Dane...   \n",
       "27  WTS Pigtronix Infinity Looper, Hungry Robot Mo...   \n",
       "28                        WTS MXR M87 Bass Compressor   \n",
       "\n",
       "                                         post_content  \\\n",
       "0   Just an awesome color for this pedal. Mint con...   \n",
       "1   https://photos.app.goo.gl/FgspRpYN8GJq3s5w5\\n\\...   \n",
       "2   r/titlegore, right?\\n\\nI've made a lot of chan...   \n",
       "3   Pics &amp; timestamp: [https://imgur.com/a/GPY...   \n",
       "4   Looking to unload some of my favorite pieces t...   \n",
       "5   ImageURL: [https://imgur.com/a/hFR7shH](https:...   \n",
       "6   Excellent-near mint condition, velcro on back....   \n",
       "7   Looking to locally sell or trade a made in Chi...   \n",
       "8   Picture: [https://imgur.com/a/HoAFmhX](https:/...   \n",
       "9   [US] Maschine Mk3 (used)\\n\\nUsed Maschine Mk3 ...   \n",
       "10  [https://imgur.com/a/vDBGh9J](https://imgur.co...   \n",
       "11  http://imgur.com/gallery/hloDV53\\n\\nAMA\\nI'm i...   \n",
       "12  **Pedals:**\\n\\n**~~SOLD~~** [~~Vox Wah Classic...   \n",
       "13  https://imgur.com/gallery/jKTGdzX\\n\\nI have a ...   \n",
       "14  {{SOLD}}\\n\\n[~~https://imgur.com/a/j3hpFqm~~](...   \n",
       "15  https://i.imgur.com/YCnTuom.jpg\\n\\nI'm looking...   \n",
       "16  Fulltone CS-OCD-Ge: $180 OBO Shipped CONUS\\n\\n...   \n",
       "17  Like New Condition - Asking $1500 OBO - comes ...   \n",
       "18  &amp;#x200B;\\n\\n**Photo Album/Time Stamp:** [h...   \n",
       "19  I am posting here to sell my **Ableton Live 10...   \n",
       "20  SOLD!\\n\\n[https://imgur.com/a/6ZL59N5](https:/...   \n",
       "21  Hi all,\\n\\nLooking to sell an AEA R84 in mint ...   \n",
       "22  WTS: \\n\\n[https://imgur.com/a/Rj6V8FH](https:/...   \n",
       "23  https://imgur.com/gallery/QoIz565\\n\\nHey guys,...   \n",
       "24  [pretty, pretty gallery](https://imgur.com/a/0...   \n",
       "25  http://imgur.com/8bzw4aU\\n\\nAll prices shipped...   \n",
       "26  Wampler Tumnus - $110\\n\\nJHS Moonshine - $100\\...   \n",
       "27  Pic w/ date [https://imgur.com/FrqLmGi](https:...   \n",
       "28  Asking for $130 + shipping, it's in like new c...   \n",
       "\n",
       "                                             post_url website  \n",
       "0   https://www.reddit.com/r/Gear4Sale/comments/l0...  Reddit  \n",
       "1   https://www.reddit.com/r/Gear4Sale/comments/ky...  Reddit  \n",
       "2   https://www.reddit.com/r/Gear4Sale/comments/ky...  Reddit  \n",
       "3   https://www.reddit.com/r/Gear4Sale/comments/kx...  Reddit  \n",
       "4   https://www.reddit.com/r/Gear4Sale/comments/kx...  Reddit  \n",
       "5   https://www.reddit.com/r/Gear4Sale/comments/kv...  Reddit  \n",
       "6   https://www.reddit.com/r/Gear4Sale/comments/ku...  Reddit  \n",
       "7   https://www.reddit.com/r/Gear4Sale/comments/ku...  Reddit  \n",
       "8   https://www.reddit.com/r/Gear4Sale/comments/kt...  Reddit  \n",
       "9   https://www.reddit.com/r/Gear4Sale/comments/kt...  Reddit  \n",
       "10  https://www.reddit.com/r/Gear4Sale/comments/kq...  Reddit  \n",
       "11  https://www.reddit.com/r/Gear4Sale/comments/kp...  Reddit  \n",
       "12  https://www.reddit.com/r/Gear4Sale/comments/ko...  Reddit  \n",
       "13  https://www.reddit.com/r/Gear4Sale/comments/kn...  Reddit  \n",
       "14  https://www.reddit.com/r/Gear4Sale/comments/kn...  Reddit  \n",
       "15  https://www.reddit.com/r/Gear4Sale/comments/km...  Reddit  \n",
       "16  https://www.reddit.com/r/Gear4Sale/comments/km...  Reddit  \n",
       "17  https://www.reddit.com/r/Gear4Sale/comments/kl...  Reddit  \n",
       "18  https://www.reddit.com/r/Gear4Sale/comments/ki...  Reddit  \n",
       "19  https://www.reddit.com/r/Gear4Sale/comments/ki...  Reddit  \n",
       "20  https://www.reddit.com/r/Gear4Sale/comments/kh...  Reddit  \n",
       "21  https://www.reddit.com/r/Gear4Sale/comments/kh...  Reddit  \n",
       "22  https://www.reddit.com/r/Gear4Sale/comments/kg...  Reddit  \n",
       "23  https://www.reddit.com/r/Gear4Sale/comments/kg...  Reddit  \n",
       "24  https://www.reddit.com/r/Gear4Sale/comments/kg...  Reddit  \n",
       "25  https://www.reddit.com/r/Gear4Sale/comments/kb...  Reddit  \n",
       "26  https://www.reddit.com/r/Gear4Sale/comments/kb...  Reddit  \n",
       "27  https://www.reddit.com/r/Gear4Sale/comments/ka...  Reddit  \n",
       "28  https://www.reddit.com/r/Gear4Sale/comments/ka...  Reddit  "
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reddit=pd.DataFrame(columns=[\"brand\",\"model\",\"price\",\"vintage\",\"color\",\"wood\",\"post_date\",\"post_title\",\"post_content\",\"post_url\"])\n",
    "k=0\n",
    "n_pages = 5\n",
    "\n",
    "print(\"Starting to scrap The Gear Page, processing the first \"+str(n_pages)+\" pages.\")\n",
    "after = \"\"\n",
    "for page_number in [i+1 for i in range(n_pages)]:\n",
    "    url = 'https://www.reddit.com/r/Gear4Sale/.json'\n",
    "    \n",
    "    if after!=\"\":\n",
    "        url += '?&after='+after\n",
    "    \n",
    "    r = requests.get(\n",
    "        url,\n",
    "        headers={'user-agent': 'Mozilla/5.0'})\n",
    "    \n",
    "    data = r.json()['data']\n",
    "    all_posts =data['children']\n",
    "    after = data[\"after\"]\n",
    "\n",
    "    for post in all_posts:\n",
    "        title = post[\"data\"][\"title\"]\n",
    "        if any(ext in title for ext in [\"sell\", \"wts\",\"Sell\",\"WTS\"]):\n",
    "            title = post[\"data\"][\"title\"]\n",
    "            content = post[\"data\"][\"selftext\"]\n",
    "            url = post[\"data\"][\"url\"]\n",
    "            post_date = datetime.datetime.fromtimestamp(float(post[\"data\"][\"created\"])).strftime(\"%Y.%m.%d\")\n",
    "            # create a new pd.Df row and insert it if not only there\n",
    "            new_row = find_relevant_information(content,title,url,post_date)\n",
    "            if new_row!=[] and not ((df_reddit['post_title'] == title) & (df_reddit['post_content'] == content)).any():\n",
    "                df_reddit.loc[k]=new_row\n",
    "                k+=1\n",
    "    r.close()\n",
    "    print(\"... \"+str(round(page_number/n_pages*100,2))+\"% done\")\n",
    "\n",
    "df_reddit[\"website\"]=\"Reddit\"\n",
    "df_reddit.to_csv(path+datetime.datetime.now().strftime(\"%Y_%m_%d\")+\"_reddit.csv\",index=False)\n",
    "df_reddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Gear Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to scrap The Gear Page, processing the first 5 pages.\n",
      "... 20.0% done\n",
      "... 40.0% done\n",
      "... 60.0% done\n",
      "... 80.0% done\n",
      "... 100.0% done\n",
      "Succesfully scraped The Gear Page, saving result to file: C:/dev/niche/guitar/data/2021_01_19_theGearPage.csv\n"
     ]
    }
   ],
   "source": [
    "tgp_base_url = \"https://www.thegearpage.net\"\n",
    "tgp_url = \"https://www.thegearpage.net/board/index.php?forums/guitar-emporium.22/\"\n",
    "df_tgp=pd.DataFrame(columns=[\"brand\",\"model\",\"price\",\"vintage\",\"color\",\"wood\",\"post_date\",\"post_title\",\"post_content\",\"post_url\"])\n",
    "k=0\n",
    "n_pages = 5\n",
    "print(\"Starting to scrap The Gear Page, processing the first \"+str(n_pages)+\" pages.\")\n",
    "\n",
    "for page_number in [i+1 for i in range(n_pages)]:\n",
    "    url = tgp_url + \"page-\"+str(page_number)\n",
    "    r = requests.get(url)\n",
    "    soup = bs4.BeautifulSoup(r.text, 'html.parser')\n",
    "    \n",
    "    for div in soup.findAll(\"div\", {\"class\":\"structItem-cell structItem-cell--main\"}):\n",
    "        # check that it is a selling post\n",
    "        if any(tag in div.text.upper() for tag in [\"FS\" or \"FOS\" or \"WTS\" or \"SELL\" or \"SALE\"]):\n",
    "            title = div.findAll(\"a\", {\"class\":\"\"})[0].text\n",
    "            \n",
    "            # get the post url and from it the content\n",
    "            post_url = tgp_base_url+div.findAll(\"a\")[1][\"href\"]\n",
    "            post_rep = requests.get(post_url)\n",
    "            post_soup = bs4.BeautifulSoup(post_rep.text, 'html.parser')\n",
    "            post_date = datetime.datetime.fromtimestamp(float(post_soup.findAll(\"time\",{\"class\":\"u-dt\"})[0][\"data-time\"])).strftime(\"%Y.%m.%d\")\n",
    "            bbWrappers = post_soup.findAll(\"div\", {\"class\":\"bbWrapper\"})\n",
    "            content = bbWrappers[0].text\n",
    "            post_rep.close()\n",
    "\n",
    "            new_row = find_relevant_information(content,title,post_url,post_date)\n",
    "            if new_row!=[] and not ((df_tgp['post_title'] == title) & (df_tgp['post_content'] == content)).any():\n",
    "                df_tgp.loc[k]=new_row\n",
    "                k+=1\n",
    "    r.close()\n",
    "    print(\"... \"+str(round(page_number/n_pages*100,2))+\"% done\")\n",
    "\n",
    "scrapping_results_file_name = path+datetime.datetime.now().strftime(\"%Y_%m_%d\")+\"_theGearPage.csv\"\n",
    "print(\"Succesfully scraped The Gear Page, saving result to file: \"+scrapping_results_file_name)\n",
    "\n",
    "df_tgp[\"website\"]=\"TheGearPage\"\n",
    "df_tgp.to_csv(scrapping_results_file_name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_kdb_instance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_scrappedGuitars_into_kdb(df_tgp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_scrappedGuitars_into_kdb(df_reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_to_HDB_all_dates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
